{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51814f9",
   "metadata": {},
   "source": [
    "# NLP-Assignment # 2\n",
    "### Name: Muhammad Bilal\n",
    "### Email: i201877@nu.edu.pk\n",
    "### Section: A.I - K\n",
    "### Roll Number: i201877\n",
    "### Course Code: AI 4001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b3340",
   "metadata": {},
   "source": [
    "### --------------------------------Transliteration: Roman Urdu - Urdu----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0163b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e8de0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1062862"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading files\n",
    "\n",
    "with open('Roman-Urdu.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    Text1 = list(reader)\n",
    "f.close()\n",
    "\n",
    "with open('Urdu.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    Text2 = list(reader)\n",
    "f.close()\n",
    "\n",
    "len(Text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811a6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "# function to tokenize urdu words based on space\n",
    "def SpaceTokenizer(text):\n",
    "    T = []\n",
    "    s = \"\"\n",
    "    for i in text[0]:\n",
    "        s = s + i\n",
    "        if i == ' ':\n",
    "            T.append(s)\n",
    "            s = \"\"\n",
    "    \n",
    "    T2 = []\n",
    "    for i in T:\n",
    "        if i != \" \":\n",
    "            T2.append(i)\n",
    "            \n",
    "    return T2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab61ed7",
   "metadata": {},
   "source": [
    "## Urdu to Roman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de43ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"ا ,آ ,ب ,پ, ت, ٹ, ث, ج, چ, ح, خ, د, ڈ, ذ, ر, ڑ, ز, ز, ژ, س, ش, ص, ض, ط, ظ, ع, غ, ف, ق, ک, گ, ل, م, ن, ں, و, ہ, ھ, ی, ے\"\n",
    "\n",
    "\n",
    "U_R = {\n",
    "    'ا' : 'a',\n",
    "    'آ' : 'Aa',\n",
    "    'ب': \"ba\" ,\n",
    "    'پ': \"pe\",\n",
    "    'ت': \"t\",\n",
    "    'ٹ': \"T\",\n",
    "    'ث': \"se\",\n",
    "    'ج': \"j\",\n",
    "    'چ': \"che\",\n",
    "    'ح': \"he\",\n",
    "    'خ': \"kh\",\n",
    "    'د': \"d\",\n",
    "    'ڈ': \"D\",\n",
    "    'ذ': \"z\",\n",
    "    'ر': \"r\",\n",
    "    'ڑ': \"r\",\n",
    "    'ز': \"Z\",\n",
    "    'ز': \"Z\",\n",
    "    'ژ': \"Ze\",\n",
    "    'س': \"S\",\n",
    "    'ش': \"sh\",\n",
    "    'ص': \"S\",\n",
    "    'ض': \"da\",\n",
    "    'ط': \"T\",\n",
    "    'ظ': \"Z\",\n",
    "    'ع': \"e\",\n",
    "    'غ': \"Gh\",\n",
    "    'ف': \"f\",\n",
    "    'ق': \"q\",\n",
    "    'ک': \"K\",\n",
    "    'گ': \"g\",\n",
    "    'ل': \"l\",\n",
    "    'م': \"m\",\n",
    "    'ن': \"n\",\n",
    "    'ں': \"n\",\n",
    "    'و': \"o\",\n",
    "    'ہ': \"h\",\n",
    "    'ھ': \"he\",\n",
    "    'ی': \"i\",\n",
    "    'ے' : \"ay\"\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d4bb2",
   "metadata": {},
   "source": [
    "1. The function UrduToRoman() uses the dictionary above to map the urdu letter to the respective english letter.\n",
    "2.To solve the problem of sound of 'و' being mapped to o and w. An assumption was made that if 'و' is the start letter of  word then it is mapped to w otherwise it is mapped to o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905b6700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " ['wKil', 'qanon', 'aiK', 'shkhS', 'jSay', 'doSray', 'shkhS', 'Ki', 'jgh', 'Kam', 'Krnay', 'ia', 'Ki', 'nmandgi', 'Krnay', 'Ka', 'akhtiar', 'heaSl', 'hota', 'hay', 'oKil', 'Sfr', 'aiK', 'shkhS', 'jo', 'teTilat', 'aor', 'Sfr', 'Ka', 'bandobaSt', 'Krta', 'hay', 'khfih', 'oKil', 'aiK', 'jaSoS']\n",
      "URdu :\n",
      " ['وکیل  قانون  ایک شخص جسے دوسرے شخص کی جگہ کام کرنے یا     کی نمائندگی کرنے کا اختیار حاصل ہوتا ہے  وکیل  سفر  ایک شخص جو تعطیلات اور سفر کا بندوبست کرتا ہے  خفیہ وکیل  ایک جاسوس ']\n"
     ]
    }
   ],
   "source": [
    "t = Text2[4]\n",
    "\n",
    "\n",
    "def UrduToRoman(t):\n",
    "    toke = SpaceTokenizer(t)\n",
    "    romans = []\n",
    "    c = True\n",
    "    for i in toke:\n",
    "        \n",
    "        s = \"\"\n",
    "        for j in i:\n",
    "            if j in U_R:\n",
    "                if c == True and j == 'و':\n",
    "                    w = 'w'\n",
    "                    c = False\n",
    "                    s = s + w\n",
    "                    \n",
    "                else:\n",
    "                    w = U_R[j]\n",
    "    #                 print(j,w)\n",
    "                    s = s + w\n",
    "        romans.append(s)\n",
    "\n",
    "    return (romans)\n",
    "print(\"Function:\\n\",UrduToRoman(t))\n",
    "print(\"URdu :\\n\",t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f4a64",
   "metadata": {},
   "source": [
    "## Evaluating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a7a577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(actual,Translated):  # revcieves list of tokenized words\n",
    "    # if the function missed some urder letters\n",
    "    \n",
    "\n",
    "    \n",
    "    Missing = dict()\n",
    "    Extra = dict()\n",
    "    correct = dict()\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    for i in actual:\n",
    "        if i != '':\n",
    "            A.append(i)\n",
    "    \n",
    "    for i in range(len(A)):\n",
    "        \n",
    "        if A[i] != ' ':\n",
    "            if len(A[i]) > len(Translated[i]):\n",
    "                ## add word in dictionary store the number of character missing \n",
    "                Missing[Translated[i]] = len(A[i]) - len(Translated[i]) \n",
    "                \n",
    "                \n",
    "            elif len(A[i]) < len(Translated[i]):\n",
    "                ## add word in dictionary store the number of extra characters\n",
    "                Extra[Translated[i]] = len(Translated[i]) - len(A[i])\n",
    "                \n",
    "            elif len(A[i]) == len(Translated[i]) and (A[i] == Translated[i]):\n",
    "                correct[Translated[i]] = len(Translated[i])\n",
    "                \n",
    "        \n",
    "    # accuracy is measured by correctly translated words / total number of words\n",
    "    Acc = len(correct) / (len(Missing) + len(Extra) + len(correct)) * 100\n",
    "        \n",
    "        # returns a dictionary containing number of missing letters , extra characters, and correct ones\n",
    "    return Missing,Extra,correct , Acc\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7d1d872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranlated:\n",
      " ['wKil', 'qanon', 'aiK', 'shkhS', 'jSay', 'doSray', 'shkhS', 'Ki', 'jgh', 'Kam', 'Krnay', 'ia', 'Ki', 'nmandgi', 'Krnay', 'Ka', 'akhtiar', 'heaSl', 'hota', 'hay', 'oKil', 'Sfr', 'aiK', 'shkhS', 'jo', 'teTilat', 'aor', 'Sfr', 'Ka', 'bandobaSt', 'Krta', 'hay', 'khfih', 'oKil', 'aiK', 'jaSoS']\n",
      "Actual:  ['wakeel qanoon 1 shakhs jisay dosray shakhs ki jagah kaam karne ya ki numaindagi karne ka ikhtiyar haasil hota hai wakeel safar 1 shakhs jo tatilat aur safar ka bandobast karta hai khufia wakeel aik jasoos']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tranlated:\\n\",UrduToRoman(t))\n",
    "print(\"Actual: \",Text1[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ce5d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "M,E,C,accuracy = Evaluate(Text1[4][0].split(' '),UrduToRoman(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2893e918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These words had missing characters:  {'wKil': 2, 'qanon': 1, 'shkhS': 1, 'jSay': 1, 'jgh': 2, 'Kam': 1, 'nmandgi': 3, 'akhtiar': 1, 'heaSl': 1, 'oKil': 2, 'Sfr': 2, 'Krta': 1, 'khfih': 1, 'jaSoS': 1}  Number of words with missing characters  14\n"
     ]
    }
   ],
   "source": [
    "print(\"These words had missing characters: \",M,\" Number of words with missing characters \",len(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "791ea07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These words had extra characters {'aiK': 2}  Number of words with Extra characters  1\n"
     ]
    }
   ],
   "source": [
    "print(\"These words had extra characters\",E,\" Number of words with Extra characters \",len(E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1a3bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These words were correctly translated:  {'hota': 4, 'jo': 2}  Number of words correctly translated  2\n"
     ]
    }
   ],
   "source": [
    "print(\"These words were correctly translated: \",C,\" Number of words correctly translated \",len(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dc4ac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation:  11.76470588235294\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Evaluation: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f19ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "397de2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wikipedia khud kisi bhi tarteeb ko nafiz nahi karta']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['wikipedia ',\n",
       " 'khud ',\n",
       " 'kisi ',\n",
       " 'bhi ',\n",
       " 'tarteeb ',\n",
       " 'ko ',\n",
       " 'nafiz ',\n",
       " 'nahi ',\n",
       " 'karta ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to tokenize english words based on space\n",
    "def SpaceTokenizer2(text):\n",
    "    T = []\n",
    "    s = \"\"\n",
    "    Text = text[0] + ' '\n",
    "    for i in Text:\n",
    "        s = s + i\n",
    "        if i == ' ':\n",
    "            T.append(s)\n",
    "            s = \"\"\n",
    "    \n",
    "    return T\n",
    "\n",
    "print(Text1[10])\n",
    "SpaceTokenizer2(Text1[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db5f03e",
   "metadata": {},
   "source": [
    "### Roman to Urdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "896f6c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = \"ا ,آ ,ب ,پ, ت, ٹ, ث, ج, چ, ح, خ, د, ڈ, ذ, ر, ڑ, ز, ز, ژ, س, ش, ص, ض, ط, ظ, ع, غ, ف, ق, ک, گ, ل, م, ن, ں, و, ہ, ھ, ی, ے\"\n",
    "\n",
    "R_U = { 'a' : 'ا', 'b' : 'ب' , 'c' : 'ث' , 'd' : 'د' , 'e' : 'ع',\n",
    "       'f' : 'ف' , 'g' : 'گ', 'h' : 'ہ' , 'i' : 'ی', 'j' : 'ج' , \n",
    "       'k' : 'ک' , 'l' : 'ل' , 'm' : 'م' , 'n' : 'ن' , 'o' : 'و', \n",
    "       'p' : 'پ' , 'q' : 'ق' , 'r' :  'ر', 's' : 'س' , 't' : 'ت' , \n",
    "       'u' : 'ع', 'v' :'و' , 'w' : 'و', 'x' : 'ذ','y' : 'ے', 'z' : 'ز'\n",
    "      }\n",
    "\n",
    "# dictionary with 2 letter english word which map to a single leter in urdu\n",
    "\n",
    "RR_U = {\n",
    "    'sh' :  'ش', 'ch' : 'چ' , 'kh' : 'خ' , 'pe' : 'پ',\n",
    "    'gh' : 'غ' , 'ay' : 'ے' , 'ze' :  'ژ' , 'oo' : 'و',\n",
    "    'ee' : 'ی' , 'aa' : 'ا' , 'oh' : 'ہ'\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# R_U = {\n",
    "#     : 'a',\n",
    "#     'آ' : 'Aa',\n",
    "#     'ب': \"ba\" ,\n",
    "#     'پ': \"pe\",\n",
    "#     'ت': \"t\",\n",
    "#     'ٹ': \"T\",\n",
    "#     'ث': \"se\",\n",
    "#     'ج': \"j\",\n",
    "#     'چ': \"che\",\n",
    "#     'ح': \"he\",\n",
    "#     'خ': \"kh\",\n",
    "#     'د': \"d\",\n",
    "#     'ڈ': \"D\",\n",
    "#     'ذ': \"z\",\n",
    "#     'ر': \"r\",\n",
    "#     'ڑ': \"r\",\n",
    "#     'ز': \"Z\",\n",
    "#     'ز': \"Z\",\n",
    "#     'ژ': \"Ze\",\n",
    "#     'س': \"S\",\n",
    "#     'ش': \"sh\",\n",
    "#     'ص': \"S\",\n",
    "#     'ض': \"da\",\n",
    "#     'ط': \"T\",\n",
    "#     'ظ': \"Z\",\n",
    "#     'ع': \"e\",\n",
    "#     'غ': \"Gh\",\n",
    "#     'ف': \"f\",\n",
    "#     'ق': \"q\",\n",
    "#     'ک': \"K\",\n",
    "#     'گ': \"g\",\n",
    "#     'ل': \"l\",\n",
    "#     'م': \"m\",\n",
    "#     'ن': \"n\",\n",
    "#     'ں': \"n\",\n",
    "#     'w': 'و',\n",
    "#     'ہ': \"h\",\n",
    "#     'ھ': \"he\",\n",
    "#     'ی': \"i\",\n",
    "#     'ے' : \"ay\"\n",
    "# }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d23cab",
   "metadata": {},
   "source": [
    "1. RomantoUrdu() method uses the above defined dictionaries to map the letters to their respective urdu letter. \n",
    "2. Additionaly another rule is defined to cater to words which have two letter pattern that map to a single urdu word e.g sh to ش \n",
    "3. There is also the condition to detect pattens containing zabr, zer , pesh to detect the next urdu letter most likely to join\n",
    "4. Normal letters are mapped to their respective urdu letter according to the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4335db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function:\n",
      " ['وہ', 'معین', 'میسار', 'کی', 'باستیی', 'مہمودیہ', 'کع', 'ایک', 'یلم', 'دوست', 'اعر', 'دیندار', 'غارانع', 'معین', 'پدا', 'ہعع']\n",
      "Urdu :\n",
      " ['woh mein misar ki bastii mhmodih ke aik ilm dost aur deendar gharane mein peda hue']\n"
     ]
    }
   ],
   "source": [
    "w = Text1[40]\n",
    "# SpaceTokenizer(w)\n",
    "def RomantoUrdu(t):\n",
    "    toke = SpaceTokenizer2(t)    \n",
    "    urdu = []\n",
    "    for i in toke:\n",
    "        s = \"\"\n",
    "        j = 0\n",
    "        i = i.lower()\n",
    "        while( j < (len(i)-1) ):\n",
    "            \n",
    "            # condition if words like ch,sh gh patern comes in the text\n",
    "            dd = i[j] + i[j+1]\n",
    "            if dd in RR_U:\n",
    "                w = RR_U[dd]\n",
    "                s = s + w\n",
    "                j = j + 2\n",
    "                \n",
    "            elif i[j] in R_U and (i[j] != 'a' or i[j] != 'i' or i[j] != o or i[j] != 'u'):\n",
    "                w = R_U[i[j]]\n",
    "                s = s + w\n",
    "                j = j + 1\n",
    "        \n",
    "        \n",
    "                # condition to detect pattens containg zabr, zer , pesh\n",
    "            elif i[j + 1] == 'a':\n",
    "                X = 'ا' + R_U[i[j]]\n",
    "                s = s + X\n",
    "                j = j + 2\n",
    "                \n",
    "            \n",
    "            elif i[j + 1] == 'i':\n",
    "                X = 'ی' + R_U[i[j]]\n",
    "                s = s + X\n",
    "                j = j + 2\n",
    "            \n",
    "                \n",
    "            elif i[j + 1] == 'o' or i[j + 1] == 'u':\n",
    "                X = 'و' + R_U[i[j]]\n",
    "                s = s + X\n",
    "                j = j + 2\n",
    "            \n",
    "            else: \n",
    "                j+=1\n",
    "            \n",
    "        urdu.append(s)\n",
    "\n",
    "    return (urdu)\n",
    "print(\"Function:\\n\",RomantoUrdu(w))\n",
    "print(\"Urdu :\\n\",w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50c6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d285603",
   "metadata": {},
   "source": [
    "# Evaluating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "759228f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranlated Sentence ['وہ', 'معین', 'میسار', 'کی', 'باستیی', 'مہمودیہ', 'کع', 'ایک', 'یلم', 'دوست', 'اعر', 'دیندار', 'غارانع', 'معین', 'پدا', 'ہعع']\n",
      "Acutal sentence ['وہ', '', '', '', 'میں', 'مصر', 'کی', 'بستی', 'محمودیہ', 'کے', 'ایک', 'علم', 'دوست', 'اور', 'دیندار', 'گھرانے', 'میں', 'پیدا', 'ہوئے']\n"
     ]
    }
   ],
   "source": [
    "word_translated = RomantoUrdu(w)\n",
    "actual_translation = Text2[40]\n",
    "print(\"Tranlated Sentence\",word_translated)\n",
    "print(\"Acutal sentence\",(actual_translation[0].split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90ae09",
   "metadata": {},
   "source": [
    "### 1. Since transliteration was done on letter to letter, for evaluation each word is evaluated character wise\n",
    "### 2. It gives us the number of missing letters and the letters wich are additional or unnececcary\n",
    "### 3. Accuracy is calculated by dividing correctly translated words in a senetence by total number of words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1a4dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(actual,Translated):  # revcieves list of tokenized words\n",
    "    # if the function missed some urder letters\n",
    "    \n",
    "\n",
    "    \n",
    "    Missing = dict()\n",
    "    Extra = dict()\n",
    "    correct = dict()\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    for i in actual:\n",
    "        if i != '':\n",
    "            A.append(i)\n",
    "    \n",
    "    for i in range(len(A)):\n",
    "        \n",
    "        if A[i] != ' ':\n",
    "            if len(A[i]) > len(Translated[i]):\n",
    "                ## add word in dictionary store the number of character missing \n",
    "                Missing[Translated[i]] = len(A[i]) - len(Translated[i]) \n",
    "                \n",
    "                \n",
    "            elif len(A[i]) < len(Translated[i]):\n",
    "                ## add word in dictionary store the number of extra characters\n",
    "                Extra[Translated[i]] = len(Translated[i]) - len(A[i])\n",
    "                \n",
    "            elif len(A[i]) == len(Translated[i]) and (A[i] == Translated[i]):\n",
    "                correct[Translated[i]] = len(Translated[i])\n",
    "                \n",
    "        \n",
    "    # accuracy is measured by correctly translated words / total number of words\n",
    "    Acc = len(correct) / (len(Missing) + len(Extra) + len(correct)) * 100\n",
    "        \n",
    "        # returns a dictionary containing number of missing letters , extra characters, and correct ones\n",
    "    return Missing,Extra,correct , Acc\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a124f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "M,E,C,accuracy = Evaluate(actual_translation[0].split(' '),word_translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ea39fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These words had missing characters:  {'پدا': 1, 'ہعع': 1}  Number of words with missing characters  2\n"
     ]
    }
   ],
   "source": [
    "print(\"These words had missing characters: \",M,\" Number of words with missing characters \",len(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35247062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These words had extra characters {'معین': 1, 'میسار': 2, 'باستیی': 2}  Number of words with Extra characters  3\n"
     ]
    }
   ],
   "source": [
    "print(\"These words had extra characters\",E,\" Number of words with Extra characters \",len(E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b0c6da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These words were correctly translated:  {'وہ': 2, 'کی': 2, 'ایک': 3, 'دوست': 4, 'دیندار': 6}  Number of words correctly translated  5\n"
     ]
    }
   ],
   "source": [
    "print(\"These words were correctly translated: \",C,\" Number of words correctly translated \",len(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fabd9bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation:  50.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Evaluation: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e338e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe467736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cd9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b924fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538cb7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67ba2b66",
   "metadata": {},
   "source": [
    "HONOR Policy: Bilal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a5f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
